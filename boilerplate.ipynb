{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './mlopt-micp')\n",
    "sys.path.insert(0, './mlopt-micp/cartpole')\n",
    "\n",
    "import optimizer\n",
    "from problem import Cartpole\n",
    "from src.ae import Encoder, get_cartpole_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x,y):\n",
    "    # x: NxD\n",
    "    # y: MxD\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    assert d == y.size(1)\n",
    "    \n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "    return torch.pow(x-y, 2).sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = Cartpole()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes: 581\n",
      "Length of feature vector: 13\n"
     ]
    }
   ],
   "source": [
    "print('Total number of classes: {}'.format(pp.n_strategies))\n",
    "print('Length of feature vector: {}'.format(pp.n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_in, dim_z = pp.n_features, 4\n",
    "\n",
    "enc = get_cartpole_encoder(dim_in, dim_z).cuda()\n",
    "enc(torch.from_numpy(pp.features[:2]).float().cuda())\n",
    "\n",
    "# training parameters\n",
    "TRAINING_ITERATIONS = int(5000)\n",
    "BATCH_SIZE = int(64)\n",
    "CHECKPOINT_AFTER = int(1250)\n",
    "SAVEPOINT_AFTER = int(2500)\n",
    "\n",
    "rand_idx = list(np.arange(0, pp.n_strategies-1))\n",
    "\n",
    "indices = [rand_idx[ii * BATCH_SIZE:(ii + 1) * BATCH_SIZE] for ii in range((len(rand_idx) + BATCH_SIZE - 1) // BATCH_SIZE)]\n",
    "random.shuffle(indices)\n",
    "\n",
    "enc_dict = {}\n",
    "str_dict = {}\n",
    "for ii in range(len(pp.features)):\n",
    "    str_idx = int(pp.labels[ii,0])\n",
    "    str_dict[ii] = str_idx\n",
    "    if str_idx in enc_dict.keys():\n",
    "        enc_dict[str_idx] += [ii]\n",
    "    else:\n",
    "        enc_dict[str_idx] = [ii]\n",
    "        \n",
    "feats = torch.from_numpy(pp.features).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1619) tensor(4.6039, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1455) tensor(4.5528, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1178) tensor(4.1660, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1367) tensor(3.6817, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1187) tensor(3.5258, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1740) tensor(3.2067, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2357) tensor(2.9375, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2140) tensor(2.5882, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1843) tensor(2.5683, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2529) tensor(2.4319, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2296) tensor(2.4675, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1947) tensor(2.4063, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2221) tensor(2.4792, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2652) tensor(2.4749, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2371) tensor(2.4477, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2482) tensor(2.2410, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2605) tensor(2.3936, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2709) tensor(2.3220, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3163) tensor(2.0255, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3325) tensor(1.9877, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4084) tensor(1.9277, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4023) tensor(1.8248, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4843) tensor(1.7643, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4973) tensor(1.7475, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4145) tensor(1.7449, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4809) tensor(1.5030, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4434) tensor(1.6470, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5005) tensor(1.7107, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5110) tensor(1.5084, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4427) tensor(1.6188, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5127) tensor(1.6829, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4973) tensor(1.6788, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4938) tensor(1.9048, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4862) tensor(1.5342, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4770) tensor(1.4886, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5183) tensor(1.6275, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5249) tensor(1.5344, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4496) tensor(1.6394, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5112) tensor(1.4592, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5382) tensor(1.5646, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4280) tensor(1.7097, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4705) tensor(1.3995, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4437) tensor(1.6335, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-01e77e2bb061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mQk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#current features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuclidean_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#compute distance between centroid & query embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mlog_p_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_p_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#compute accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(enc.parameters(),lr=3e-4)\n",
    "N = pp.n_strategies # number of classes in training set\n",
    "Nc = 100 # number of classes per episode\n",
    "Ns = 20  # number of support examples per class\n",
    "Nq = 20  # number of query examples per class\n",
    "training_iters = 10000\n",
    "for tt in range(training_iters):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    #sample classes for this iter\n",
    "    V = np.random.randint(0, pp.n_strategies, Nc)\n",
    "    Sk = {}  # support examples\n",
    "    Qk = {}  # query examples\n",
    "    ck = torch.zeros((Nc, dim_z))\n",
    "\n",
    "    for ii, v in enumerate(V):\n",
    "        if len(enc_dict[v]) <= Ns: #if not enough examples for support\n",
    "            Sk[v] = enc_dict[v]\n",
    "            Qk[v] = enc_dict[v]\n",
    "        else:\n",
    "            Sk[v] = random.sample(enc_dict[v], Ns)\n",
    "            Qk[v] = [kk for kk in enc_dict[v] if kk not in Sk[v]]\n",
    "            if len(Qk[v]) > Nq: #if not enough examples for query\n",
    "                Qk[v] = random.sample(Qk[v], Nq)\n",
    "        enc_support = enc(feats[Sk[v],:])\n",
    "        ck[ii,:] = torch.mean(enc_support, axis=0).float().cuda()\n",
    "        \n",
    "    losses = torch.zeros(len(V))\n",
    "    correct = torch.zeros(len(V))\n",
    "    total = torch.zeros(len(V))\n",
    "    for ii, v in enumerate(V):\n",
    "        fx = enc(feats[Qk[v],:]) #current features\n",
    "        dists = euclidean_dist(fx.cuda(),ck.cuda()) #compute distance between centroid & query embeds\n",
    "        log_p_y = dists[:,ii] + torch.log(torch.sum(torch.exp(-dists)+1e-6, axis=1))\n",
    "        losses[ii] = log_p_y.mean()\n",
    "        #compute accuracy\n",
    "        correct[ii] = torch.sum(torch.argmin(dists,axis=1)==ii)\n",
    "        total[ii] = len(Qk[v])\n",
    "        \n",
    "    acc = torch.sum(correct)/torch.sum(total)\n",
    "    \n",
    "    if tt % 50 == 0: #print for debug\n",
    "        print(acc, torch.mean(losses))\n",
    "    \n",
    "    torch.mean(losses).backward()\n",
    "    torch.nn.utils.clip_grad_norm_(enc.parameters(), 1.)\n",
    "    total_norm = 0.\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test script\n",
    "n_train_strategies = pp.n_strategies #store how many strats in train set\n",
    "c_k = torch.zeros((n_train_strategies,4)) \n",
    "embeddings = enc(feats) #embed training points\n",
    "for ii in range(n_train_strategies): #compute train centroids\n",
    "    inds = enc_dict[ii]\n",
    "    c_k[ii,:] = torch.mean(embeddings[inds,:],axis=0).cuda()\n",
    "\n",
    "#compute strategy dictionary for all problems\n",
    "pp.training_batch_percentage = 1.\n",
    "pp.construct_strategies()\n",
    "strat_lookup = {}\n",
    "for k, v in pp.strategy_dict.items():\n",
    "    strat_lookup[v[0]] = v[1:]\n",
    "\n",
    "#setup for test\n",
    "test_feats = torch.from_numpy(pp.features[int(0.9*pp.n_probs):,:]).float().cuda()\n",
    "test_enc = enc(test_feats).cuda()\n",
    "test_dists = torch.cdist(test_enc,c_k.cuda()).detach().cpu().numpy()\n",
    "test_start = int(0.9*pp.n_probs)\n",
    "n_test = int(0.1*pp.n_probs)\n",
    "ind_max = np.argsort(test_dists)[:,:pp.n_evals]\n",
    "feasible = np.zeros(n_test)\n",
    "costs = np.zeros(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeded at 1 with 4 tries\n",
      "Succeded at 2 with 0 tries\n",
      "Succeded at 4 with 7 tries\n",
      "Succeded at 6 with 1 tries\n",
      "Succeded at 7 with 1 tries\n",
      "Succeded at 8 with 0 tries\n",
      "Succeded at 10 with 3 tries\n",
      "Succeded at 11 with 0 tries\n",
      "Succeded at 12 with 1 tries\n",
      "Succeded at 14 with 9 tries\n",
      "Succeded at 17 with 3 tries\n",
      "Succeded at 18 with 7 tries\n",
      "Succeded at 21 with 9 tries\n",
      "Succeded at 24 with 0 tries\n",
      "Succeded at 26 with 0 tries\n",
      "Succeded at 27 with 3 tries\n",
      "Succeded at 28 with 2 tries\n",
      "Succeded at 29 with 7 tries\n",
      "Succeded at 31 with 1 tries\n",
      "Succeded at 32 with 0 tries\n",
      "Succeded at 34 with 8 tries\n",
      "Succeded at 36 with 0 tries\n",
      "Succeded at 37 with 0 tries\n",
      "Succeded at 38 with 0 tries\n",
      "Succeded at 39 with 0 tries\n",
      "Succeded at 41 with 4 tries\n",
      "Succeded at 43 with 3 tries\n",
      "Succeded at 44 with 3 tries\n",
      "Succeded at 45 with 0 tries\n",
      "Succeded at 46 with 4 tries\n",
      "Succeded at 47 with 6 tries\n",
      "Succeded at 48 with 1 tries\n",
      "Succeded at 49 with 2 tries\n",
      "Succeded at 50 with 2 tries\n",
      "Succeded at 52 with 4 tries\n",
      "Succeded at 54 with 0 tries\n",
      "Succeded at 60 with 0 tries\n",
      "Succeded at 61 with 6 tries\n",
      "Succeded at 62 with 1 tries\n",
      "Succeded at 63 with 0 tries\n",
      "Succeded at 65 with 2 tries\n",
      "Succeded at 66 with 4 tries\n",
      "Succeded at 67 with 4 tries\n",
      "Succeded at 73 with 1 tries\n",
      "Succeded at 74 with 3 tries\n",
      "Succeded at 75 with 7 tries\n",
      "Succeded at 77 with 0 tries\n",
      "Succeded at 78 with 4 tries\n",
      "Succeded at 79 with 7 tries\n",
      "Succeded at 80 with 2 tries\n",
      "Succeded at 81 with 0 tries\n",
      "Succeded at 82 with 1 tries\n",
      "Succeded at 83 with 1 tries\n",
      "Succeded at 84 with 6 tries\n",
      "Succeded at 87 with 3 tries\n",
      "Succeded at 88 with 4 tries\n",
      "Succeded at 89 with 5 tries\n",
      "Succeded at 90 with 0 tries\n",
      "Succeded at 91 with 2 tries\n",
      "Succeded at 92 with 0 tries\n",
      "Succeded at 94 with 0 tries\n",
      "Succeded at 95 with 2 tries\n",
      "Succeded at 97 with 4 tries\n",
      "Succeded at 98 with 8 tries\n"
     ]
    }
   ],
   "source": [
    "prob_success = False\n",
    "\n",
    "for ii in range(n_test):\n",
    "    for jj in range(pp.n_evals):\n",
    "        y_guess = strat_lookup[ind_max[ii,jj]]\n",
    "        try:\n",
    "            prob_success, cost, solve_time = pp.solve_mlopt_prob_with_idx(ii+test_start, y_guess)\n",
    "            if prob_success:\n",
    "                feasible[ii] = 1.\n",
    "                costs[ii] = cost\n",
    "                print('Succeded at {} with {} tries'.format(ii,jj+1))\n",
    "                break\n",
    "        except:\n",
    "            print('mosek failed at '.format(ii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_acc = sum(sum(np.equal(ind_max,pp.labels[test_start:,0][:,None])))/(0.1*pp.n_probs)\n",
    "global_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6464646464646465"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(feasible[:ii])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlopt",
   "language": "python",
   "name": "mlopt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
