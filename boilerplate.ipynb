{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.3 (default, Mar  6 2020, 14:15:08) \\n[GCC 5.4.0 20160609]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './mlopt-micp')\n",
    "sys.path.insert(0, './mlopt-micp/cartpole')\n",
    "\n",
    "import optimizer\n",
    "from problem import Cartpole\n",
    "from src.ae import Encoder, get_cartpole_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x,y):\n",
    "    # x: NxD\n",
    "    # y: MxD\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    assert d == y.size(1)\n",
    "    \n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "    return torch.pow(x-y, 2).sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = Cartpole()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes: 581\n",
      "Length of feature vector: 13\n"
     ]
    }
   ],
   "source": [
    "print('Total number of classes: {}'.format(pp.n_strategies))\n",
    "print('Length of feature vector: {}'.format(pp.n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0861, 0.0449, 0.0254],\n",
       "        [0.0000, 0.0690, 0.1079, 0.0422]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_in, dim_z = pp.n_features, 4\n",
    "\n",
    "enc = get_cartpole_encoder(dim_in, dim_z)\n",
    "enc(torch.from_numpy(pp.features[:2]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dict = {}\n",
    "str_dict = {}\n",
    "encodings = enc(torch.from_numpy(pp.features).float())\n",
    "\n",
    "for ii in range(len(pp.features)):\n",
    "    str_idx = int(pp.labels[ii,0])\n",
    "    str_dict[ii] = str_idx\n",
    "    if str_idx in enc_dict.keys():\n",
    "        enc_dict[str_idx] += [ii]\n",
    "    else:\n",
    "        enc_dict[str_idx] = [ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "TRAINING_ITERATIONS = int(5000)\n",
    "BATCH_SIZE = int(64)\n",
    "CHECKPOINT_AFTER = int(1250)\n",
    "SAVEPOINT_AFTER = int(2500)\n",
    "\n",
    "rand_idx = list(np.arange(0, pp.n_strategies-1))\n",
    "\n",
    "indices = [rand_idx[ii * BATCH_SIZE:(ii + 1) * BATCH_SIZE] for ii in range((len(rand_idx) + BATCH_SIZE - 1) // BATCH_SIZE)]\n",
    "random.shuffle(indices)\n",
    "\n",
    "optimizer = optim.Adam(enc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = pp.n_strategies # number of classes in training set\n",
    "Nc = 10  # number of classes per episode\n",
    "Ns = 15  # number of support examples per class\n",
    "Nq = 8  # number of query examples per class\n",
    "\n",
    "V = np.random.randint(0, pp.n_strategies, Nc)\n",
    "Sk = {}  # support examples\n",
    "Qk = {}  # query examples\n",
    "ck = torch.zeros((Nc, dim_z))\n",
    "\n",
    "for ii, v in enumerate(V):\n",
    "    if len(enc_dict[v]) < Ns:\n",
    "        Sk[v] = enc_dict[v]\n",
    "        Qk[v] = enc_dict[v]\n",
    "    else:\n",
    "        Sk[v] = random.sample(enc_dict[v], Ns)\n",
    "        Qk[v] = [kk for kk in enc_dict[v] if kk not in Sk[v]]\n",
    "        if len(Qk[v]) > Nq:\n",
    "            Qk[v] = random.sample(Qk[v], Nq)\n",
    "    ck[ii] = torch.mean(encodings[Sk[v]], axis=0)\n",
    "\n",
    "loss = 0.\n",
    "for ii, v in enumerate(V):\n",
    "    local_loss = 0.\n",
    "    fx = encodings[Qk[v]]\n",
    "    centr_dist = (fx - ck[ii]).pow(2).sum(dim=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0.\n",
    "for ii in range(len(V)):\n",
    "    local_loss = 0.\n",
    "    fx = encodings[Qk[v]]\n",
    "    dists = euclidean_dist(fx, ck)\n",
    "    log_p_y = dists[:,ii] + torch.log(torch.sum(torch.exp(-dists), axis=1))\n",
    "    loss += log_p_y.mean()\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 0\n",
    "for epoch in range(TRAINING_ITERATIONS):\n",
    "    iter_count = 0\n",
    "    for ii, idx in enumerate(indices):\n",
    "        optimizer.zero_grad()\n",
    "        action = torch.empty(NUM_DATA, dim_u)\n",
    "\n",
    "        encodings_idx = enc(torch.from_numpy(pp.features[idx]).float())\n",
    "        loss = compute_loss(encodings_idx, str_dict)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if itr % CHECKPOINT_AFTER == 0:\n",
    "            print('Avg. loss: {}'.format(loss.item()))\n",
    "\n",
    "        if itr % SAVEPOINT_AFTER == 0:\n",
    "            torch.save(model.state_dict(), fn_pt_model)\n",
    "\n",
    "        iter_count += 1\n",
    "        itr += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlopt",
   "language": "python",
   "name": "mlopt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
